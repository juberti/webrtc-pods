diff --git a/sdk/BUILD.gn b/sdk/BUILD.gn
index 19e612e2d1..4b3f3478bb 100644
--- a/sdk/BUILD.gn
+++ b/sdk/BUILD.gn
@@ -246,6 +246,8 @@ if (is_ios || is_mac) {
         visibility = [ "*" ]
 
         sources = [
+          "objc/native/src/audio/audio_source_sink.h",
+          "objc/native/src/audio/audio_source_sink.mm",
           "objc/native/src/audio/audio_device_ios.h",
           "objc/native/src/audio/audio_device_ios.mm",
           "objc/native/src/audio/audio_device_module_ios.h",
@@ -865,6 +867,8 @@ if (is_ios || is_mac) {
         "objc/api/peerconnection/RTCAudioSource+Private.h",
         "objc/api/peerconnection/RTCAudioSource.h",
         "objc/api/peerconnection/RTCAudioSource.mm",
+        "objc/api/peerconnection/RTCAudioSink.h",
+        "objc/api/peerconnection/RTCAudioSink.mm",
         "objc/api/peerconnection/RTCAudioTrack+Private.h",
         "objc/api/peerconnection/RTCAudioTrack.h",
         "objc/api/peerconnection/RTCAudioTrack.mm",
@@ -1255,6 +1259,7 @@ if (is_ios || is_mac) {
           "objc/helpers/RTCDispatcher.h",
           "objc/helpers/UIDevice+RTCDevice.h",
           "objc/api/peerconnection/RTCAudioSource.h",
+          "objc/api/peerconnection/RTCAudioSink.h",
           "objc/api/peerconnection/RTCAudioTrack.h",
           "objc/api/peerconnection/RTCConfiguration.h",
           "objc/api/peerconnection/RTCDataChannel.h",
@@ -1366,6 +1371,7 @@ if (is_ios || is_mac) {
 
         sources = [
           "objc/api/peerconnection/RTCAudioSource.h",
+          "objc/api/peerconnection/RTCAudioSink.h",
           "objc/api/peerconnection/RTCAudioTrack.h",
           "objc/api/peerconnection/RTCCertificate.h",
           "objc/api/peerconnection/RTCConfiguration.h",
diff --git a/sdk/objc/api/peerconnection/RTCAudioSink.h b/sdk/objc/api/peerconnection/RTCAudioSink.h
new file mode 100644
index 0000000000..de8a1d7449
--- /dev/null
+++ b/sdk/objc/api/peerconnection/RTCAudioSink.h
@@ -0,0 +1,25 @@
+#import <Foundation/Foundation.h>
+#import <AVFoundation/AVFoundation.h>
+
+#import "RTCMacros.h"
+
+NS_ASSUME_NONNULL_BEGIN
+
+RTC_OBJC_EXPORT
+@interface RTC_OBJC_TYPE (RTCAudioSink) : NSObject
+
+- (instancetype)init;
+- (void)onLocalAudioFrameWithFlags:(AudioUnitRenderActionFlags *)flags
+                    timeStamp:(const AudioTimeStamp *)timeStamp
+                    busNumber:(uint32_t)busNumber
+                    numFrames:(uint32_t)numFrames
+                    ioData:(AudioBufferList *)ioData;
+
+- (void)onRemoteAudioFrameWithFlags:(AudioUnitRenderActionFlags *)flags
+                    timeStamp:(const AudioTimeStamp *)timeStamp
+                    busNumber:(uint32_t)busNumber
+                    numFrames:(uint32_t)numFrames
+                    ioData:(AudioBufferList *)ioData;
+@end
+
+NS_ASSUME_NONNULL_END
diff --git a/sdk/objc/api/peerconnection/RTCAudioSink.mm b/sdk/objc/api/peerconnection/RTCAudioSink.mm
new file mode 100644
index 0000000000..6f2da27e86
--- /dev/null
+++ b/sdk/objc/api/peerconnection/RTCAudioSink.mm
@@ -0,0 +1,34 @@
+/*
+ *  Copyright 2016 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#import "RTCAudioSink.h"
+#import "base/RTCLogging.h"
+
+@implementation RTC_OBJC_TYPE (RTCAudioSink) {
+}
+
+- (instancetype)init {
+  self = [super init];
+  return self;
+}
+
+- (void)onLocalAudioFrameWithFlags:(AudioUnitRenderActionFlags *)flags
+                    timeStamp:(const AudioTimeStamp *)timeStamp
+                    busNumber:(uint32_t)busNumber
+                    numFrames:(uint32_t)numFrames
+                    ioData:(AudioBufferList *)ioData { }
+
+- (void)onRemoteAudioFrameWithFlags:(AudioUnitRenderActionFlags *)flags
+                    timeStamp:(const AudioTimeStamp *)timeStamp
+                    busNumber:(uint32_t)busNumber
+                    numFrames:(uint32_t)numFrames
+                    ioData:(AudioBufferList *)ioData { }
+
+@end
+
diff --git a/sdk/objc/api/peerconnection/RTCPeerConnectionFactory+Native.h b/sdk/objc/api/peerconnection/RTCPeerConnectionFactory+Native.h
index f361b9f0ea..8890a6c248 100644
--- a/sdk/objc/api/peerconnection/RTCPeerConnectionFactory+Native.h
+++ b/sdk/objc/api/peerconnection/RTCPeerConnectionFactory+Native.h
@@ -69,7 +69,9 @@ NS_ASSUME_NONNULL_BEGIN
 
 - (instancetype)
     initWithEncoderFactory:(nullable id<RTC_OBJC_TYPE(RTCVideoEncoderFactory)>)encoderFactory
-            decoderFactory:(nullable id<RTC_OBJC_TYPE(RTCVideoDecoderFactory)>)decoderFactory;
+            decoderFactory:(nullable id<RTC_OBJC_TYPE(RTCVideoDecoderFactory)>)decoderFactory
+                 audioSink:(nullable RTC_OBJC_TYPE(RTCAudioSink) *)audioSink;
+
 
 /** Initialize an RTCPeerConnection with a configuration, constraints, and
  *  dependencies.
diff --git a/sdk/objc/api/peerconnection/RTCPeerConnectionFactory.h b/sdk/objc/api/peerconnection/RTCPeerConnectionFactory.h
index 78913527c0..77652ebad9 100644
--- a/sdk/objc/api/peerconnection/RTCPeerConnectionFactory.h
+++ b/sdk/objc/api/peerconnection/RTCPeerConnectionFactory.h
@@ -15,6 +15,7 @@
 NS_ASSUME_NONNULL_BEGIN
 
 @class RTC_OBJC_TYPE(RTCAudioSource);
+@class RTC_OBJC_TYPE(RTCAudioSink);
 @class RTC_OBJC_TYPE(RTCAudioTrack);
 @class RTC_OBJC_TYPE(RTCConfiguration);
 @class RTC_OBJC_TYPE(RTCMediaConstraints);
@@ -41,6 +42,12 @@ RTC_OBJC_EXPORT
     initWithEncoderFactory:(nullable id<RTC_OBJC_TYPE(RTCVideoEncoderFactory)>)encoderFactory
             decoderFactory:(nullable id<RTC_OBJC_TYPE(RTCVideoDecoderFactory)>)decoderFactory;
 
+/* Initialize object with injectable video encoder/decoder factories and audioSink */
+- (instancetype)
+    initWithEncoderFactory:(nullable id<RTC_OBJC_TYPE(RTCVideoEncoderFactory)>)encoderFactory
+            decoderFactory:(nullable id<RTC_OBJC_TYPE(RTCVideoDecoderFactory)>)decoderFactory
+            audioSink:(nullable RTC_OBJC_TYPE(RTCAudioSink) *)audioSink;
+
 /** Initialize an RTCAudioSource with constraints. */
 - (RTC_OBJC_TYPE(RTCAudioSource) *)audioSourceWithConstraints:
     (nullable RTC_OBJC_TYPE(RTCMediaConstraints) *)constraints;
diff --git a/sdk/objc/api/peerconnection/RTCPeerConnectionFactory.mm b/sdk/objc/api/peerconnection/RTCPeerConnectionFactory.mm
index 63ba934e3d..ae8a8fc82b 100644
--- a/sdk/objc/api/peerconnection/RTCPeerConnectionFactory.mm
+++ b/sdk/objc/api/peerconnection/RTCPeerConnectionFactory.mm
@@ -50,6 +50,9 @@
 
 #if defined(WEBRTC_IOS)
 #import "sdk/objc/native/api/audio_device_module.h"
+#import "sdk/objc/native/src/audio/audio_source_sink.h"
+#import "sdk/objc/native/src/audio/audio_device_module_ios.h"
+#import "RTCAudioSink.h"
 #endif
 
 // Adding the nogncheck to disable the including header check.
@@ -70,12 +73,23 @@ @implementation RTC_OBJC_TYPE (RTCPeerConnectionFactory) {
 
 - (rtc::scoped_refptr<webrtc::AudioDeviceModule>)audioDeviceModule {
 #if defined(WEBRTC_IOS)
+  RTCLogInfo(@"Creating AudioDeviceModule without AudioSourceSink");
   return webrtc::CreateAudioDeviceModule();
 #else
   return nullptr;
 #endif
 }
 
+- (rtc::scoped_refptr<webrtc::AudioDeviceModule>)audioDeviceModuleWithAudioSink:(nullable RTC_OBJC_TYPE(RTCAudioSink) *)audioSink {
+#if defined(WEBRTC_IOS)
+  RTCLogInfo(@"Creating AudioDeviceModule with AudioSourceSink");
+  webrtc::AudioSourceSink *sink = new webrtc::AudioSourceSink(audioSink);
+  return webrtc::CreateAudioDeviceModule(sink);
+#else
+  return nullptr;
+#endif
+}
+
 - (instancetype)init {
 #ifdef HAVE_NO_MEDIA
   return [self initWithNoMedia];
@@ -95,6 +109,13 @@ - (instancetype)init {
 - (instancetype)
     initWithEncoderFactory:(nullable id<RTC_OBJC_TYPE(RTCVideoEncoderFactory)>)encoderFactory
             decoderFactory:(nullable id<RTC_OBJC_TYPE(RTCVideoDecoderFactory)>)decoderFactory {
+  return [self initWithEncoderFactory:encoderFactory decoderFactory:decoderFactory audioSink:nullptr];
+}
+
+- (instancetype)
+    initWithEncoderFactory:(nullable id<RTC_OBJC_TYPE(RTCVideoEncoderFactory)>)encoderFactory
+            decoderFactory:(nullable id<RTC_OBJC_TYPE(RTCVideoDecoderFactory)>)decoderFactory
+                 audioSink:(nullable RTC_OBJC_TYPE(RTCAudioSink) *)audioSink {
 #ifdef HAVE_NO_MEDIA
   return [self initWithNoMedia];
 #else
@@ -110,7 +131,7 @@ - (instancetype)init {
                        nativeAudioDecoderFactory:webrtc::CreateBuiltinAudioDecoderFactory()
                        nativeVideoEncoderFactory:std::move(native_encoder_factory)
                        nativeVideoDecoderFactory:std::move(native_decoder_factory)
-                               audioDeviceModule:[self audioDeviceModule]
+                               audioDeviceModule:[self audioDeviceModuleWithAudioSink:audioSink]
                            audioProcessingModule:nullptr];
 #endif
 }
diff --git a/sdk/objc/native/api/audio_device_module.h b/sdk/objc/native/api/audio_device_module.h
index 3405469709..5e7f5a150f 100644
--- a/sdk/objc/native/api/audio_device_module.h
+++ b/sdk/objc/native/api/audio_device_module.h
@@ -17,13 +17,17 @@
 
 namespace webrtc {
 
+class AudioSourceSink;
+
 // If `bypass_voice_processing` is true, WebRTC will attempt to disable hardware
 // audio processing on iOS.
 // Warning: Setting `bypass_voice_processing` will have unpredictable
 // consequences for the audio path in the device. It is not advisable to use in
 // most scenarios.
 rtc::scoped_refptr<AudioDeviceModule> CreateAudioDeviceModule(
-    bool bypass_voice_processing = false);
+    AudioSourceSink* audio_sink = nullptr,
+    bool bypass_voice_processing = false
+);
 
 }  // namespace webrtc
 
diff --git a/sdk/objc/native/api/audio_device_module.mm b/sdk/objc/native/api/audio_device_module.mm
index 3c2790e38d..9673309aa7 100644
--- a/sdk/objc/native/api/audio_device_module.mm
+++ b/sdk/objc/native/api/audio_device_module.mm
@@ -17,10 +17,11 @@
 
 namespace webrtc {
 
-rtc::scoped_refptr<AudioDeviceModule> CreateAudioDeviceModule(bool bypass_voice_processing) {
+rtc::scoped_refptr<AudioDeviceModule> CreateAudioDeviceModule(AudioSourceSink* audio_sink,
+                                                              bool bypass_voice_processing) {
   RTC_DLOG(LS_INFO) << __FUNCTION__;
 #if defined(WEBRTC_IOS)
-  return new rtc::RefCountedObject<ios_adm::AudioDeviceModuleIOS>(bypass_voice_processing);
+  return new rtc::RefCountedObject<ios_adm::AudioDeviceModuleIOS>(audio_sink, bypass_voice_processing);
 #else
   RTC_LOG(LS_ERROR) << "current platform is not supported => this module will self destruct!";
   return nullptr;

diff --git a/sdk/objc/native/src/audio/audio_device_ios.h b/sdk/objc/native/src/audio/audio_device_ios.h
index 5afc49a461..d2ecf1008a 100644
--- a/sdk/objc/native/src/audio/audio_device_ios.h
+++ b/sdk/objc/native/src/audio/audio_device_ios.h
@@ -26,6 +26,7 @@ RTC_FWD_DECL_OBJC_CLASS(RTCNativeAudioSessionDelegateAdapter);
 
 namespace webrtc {
 
+class AudioSourceSink;
 class FineAudioBuffer;
 
 namespace ios_adm {
@@ -161,6 +162,8 @@ class AudioDeviceIOS : public AudioDeviceGeneric,
   // Handles messages from posts.
   void OnMessage(rtc::Message* msg) override;
 
+  void AddAudioSourceSink(AudioSourceSink* audioSink);
+
   bool IsInterrupted();
 
  private:
@@ -300,6 +303,8 @@ class AudioDeviceIOS : public AudioDeviceGeneric,
 
   // Contains the time for when the last output volume change was detected.
   int64_t last_output_volume_change_time_ RTC_GUARDED_BY(thread_checker_);
+
+  AudioSourceSink* audioSink_;
 };
 }  // namespace ios_adm
 }  // namespace webrtc
diff --git a/sdk/objc/native/src/audio/audio_device_ios.mm b/sdk/objc/native/src/audio/audio_device_ios.mm
index 248f3fcfd2..fb6ebf08d5 100644
--- a/sdk/objc/native/src/audio/audio_device_ios.mm
+++ b/sdk/objc/native/src/audio/audio_device_ios.mm
@@ -33,6 +33,8 @@
 #import "components/audio/RTCAudioSessionConfiguration.h"
 #import "components/audio/RTCNativeAudioSessionDelegateAdapter.h"
 
+#import "audio_source_sink.h"
+
 namespace webrtc {
 namespace ios_adm {
 
@@ -418,6 +420,8 @@ static void LogDeviceInfo() {
   // Use the FineAudioBuffer instance to convert between native buffer size
   // and the 10ms buffer size used by WebRTC.
   fine_audio_buffer_->DeliverRecordedData(record_audio_buffer_, kFixedRecordDelayEstimate);
+
+  audioSink_->OnLocalAudioFrame(flags, time_stamp, bus_number, num_frames, &audio_buffer_list);
   return noErr;
 }
 
@@ -477,6 +481,8 @@ static void LogDeviceInfo() {
   fine_audio_buffer_->GetPlayoutData(
       rtc::ArrayView<int16_t>(static_cast<int16_t*>(audio_buffer->mData), num_frames),
       kFixedPlayoutDelayEstimate);
+
+  audioSink_->OnRemoteAudioFrame(flags, time_stamp, bus_number, num_frames, io_data);
   return noErr;
 }
 
@@ -1162,5 +1168,10 @@ static void LogDeviceInfo() {
   return 0;
 }
 
+void AudioDeviceIOS::AddAudioSourceSink(webrtc::AudioSourceSink* audioSink) {
+  RTC_LOG(LS_VERBOSE) << "AddAudioSourceSink for AudioDeviceIOS" << audioSink;
+  audioSink_ = audioSink;
+}
+
 }  // namespace ios_adm
 }  // namespace webrtc
diff --git a/sdk/objc/native/src/audio/audio_device_module_ios.h b/sdk/objc/native/src/audio/audio_device_module_ios.h
index 9bcf114e32..ef24bd071d 100644
--- a/sdk/objc/native/src/audio/audio_device_module_ios.h
+++ b/sdk/objc/native/src/audio/audio_device_module_ios.h
@@ -23,6 +23,7 @@
 namespace webrtc {
 
 class AudioDeviceGeneric;
+class AudioSourceSink;
 
 namespace ios_adm {
 
@@ -30,7 +31,7 @@ class AudioDeviceModuleIOS : public AudioDeviceModule {
  public:
   int32_t AttachAudioBuffer();
 
-  explicit AudioDeviceModuleIOS(bool bypass_voice_processing);
+  AudioDeviceModuleIOS(AudioSourceSink* audio_sink, bool bypass_voice_processing);
   ~AudioDeviceModuleIOS() override;
 
   // Retrieve the currently utilized audio layer
@@ -125,7 +126,6 @@ class AudioDeviceModuleIOS : public AudioDeviceModule {
   int32_t EnableBuiltInNS(bool enable) override;
 
   int32_t GetPlayoutUnderrunCount() const override;
-
 #if defined(WEBRTC_IOS)
   int GetPlayoutAudioParameters(AudioParameters* params) const override;
   int GetRecordAudioParameters(AudioParameters* params) const override;
@@ -136,6 +136,7 @@ class AudioDeviceModuleIOS : public AudioDeviceModule {
   const std::unique_ptr<TaskQueueFactory> task_queue_factory_;
   std::unique_ptr<AudioDeviceIOS> audio_device_;
   std::unique_ptr<AudioDeviceBuffer> audio_device_buffer_;
+  AudioSourceSink* audio_sink_;
 };
 }  // namespace ios_adm
 }  // namespace webrtc
diff --git a/sdk/objc/native/src/audio/audio_device_module_ios.mm b/sdk/objc/native/src/audio/audio_device_module_ios.mm
index 33ba926bec..1f59395bd9 100644
--- a/sdk/objc/native/src/audio/audio_device_module_ios.mm
+++ b/sdk/objc/native/src/audio/audio_device_module_ios.mm
@@ -21,6 +21,7 @@
 
 #if defined(WEBRTC_IOS)
 #include "audio_device_ios.h"
+#include "audio_source_sink.h"
 #endif
 
 #define CHECKinitialized_() \
@@ -40,11 +41,15 @@
 namespace webrtc {
 namespace ios_adm {
 
-AudioDeviceModuleIOS::AudioDeviceModuleIOS(bool bypass_voice_processing)
-    : bypass_voice_processing_(bypass_voice_processing),
-      task_queue_factory_(CreateDefaultTaskQueueFactory()) {
+AudioDeviceModuleIOS::AudioDeviceModuleIOS(AudioSourceSink* audio_sink, bool bypass_voice_processing)
+     : bypass_voice_processing_(bypass_voice_processing),
+       task_queue_factory_(CreateDefaultTaskQueueFactory()) {
   RTC_LOG(LS_INFO) << "current platform is IOS";
   RTC_LOG(LS_INFO) << "iPhone Audio APIs will be utilized.";
+  if (audio_sink) {
+    RTC_LOG(LS_INFO) << "Initializing AudioDeviceModuleIOS with AudioSink";
+  }
+  audio_sink_ = audio_sink;
 }
 
   int32_t AudioDeviceModuleIOS::AttachAudioBuffer() {
diff --git a/sdk/objc/native/src/audio/audio_source_sink.h b/sdk/objc/native/src/audio/audio_source_sink.h
new file mode 100644
index 0000000000..06eb4ef672
--- /dev/null
+++ b/sdk/objc/native/src/audio/audio_source_sink.h
@@ -0,0 +1,28 @@
+#ifndef SDK_OBJC_NATIVE_SRC_AUDIO_AUDIO_SOURCE_SINK_H_
+#define SDK_OBJC_NATIVE_SRC_AUDIO_AUDIO_SOURCE_SINK_H_
+
+#include "sdk/objc/base/RTCMacros.h"
+#include <AudioUnit/AudioUnit.h>
+
+RTC_FWD_DECL_OBJC_CLASS(RTCAudioSink);
+
+namespace webrtc {
+    class AudioSourceSink {
+        public:
+        AudioSourceSink(RTCAudioSink* sink);
+        void OnLocalAudioFrame(AudioUnitRenderActionFlags* flags,
+                                          const AudioTimeStamp* time_stamp,
+                                          UInt32 bus_number,
+                                          UInt32 num_frames,
+                                          AudioBufferList* io_data);
+        void OnRemoteAudioFrame(AudioUnitRenderActionFlags* flags,
+                                          const AudioTimeStamp* time_stamp,
+                                          UInt32 bus_number,
+                                          UInt32 num_frames,
+                                          AudioBufferList* io_data);
+        private:
+        __weak RTCAudioSink *sink_;
+    };
+}
+
+#endif // SDK_OBJC_NATIVE_SRC_AUDIO_AUDIO_SOURCE_SINK_H_
diff --git a/sdk/objc/native/src/audio/audio_source_sink.mm b/sdk/objc/native/src/audio/audio_source_sink.mm
new file mode 100644
index 0000000000..11cf958591
--- /dev/null
+++ b/sdk/objc/native/src/audio/audio_source_sink.mm
@@ -0,0 +1,28 @@
+#import "sdk/objc/native/src/audio/audio_source_sink.h"
+#import "sdk/objc/api/peerconnection/RTCAudioSink.h"
+#import "base/RTCLogging.h"
+#import "rtc_base/logging.h"
+
+namespace webrtc {
+  AudioSourceSink::AudioSourceSink(RTCAudioSink *sink) {
+    sink_ = sink;
+  }
+
+  void AudioSourceSink::OnLocalAudioFrame(AudioUnitRenderActionFlags* flags,
+                                          const AudioTimeStamp* time_stamp,
+                                          UInt32 bus_number,
+                                          UInt32 num_frames,
+                                          AudioBufferList* io_data) {
+    RTC_LOG(LS_VERBOSE) << __FUNCTION__;
+    [sink_ onLocalAudioFrameWithFlags:flags timeStamp:time_stamp busNumber:bus_number numFrames:num_frames ioData:io_data];
+  }
+
+  void AudioSourceSink::OnRemoteAudioFrame(AudioUnitRenderActionFlags* flags,
+                                          const AudioTimeStamp* time_stamp,
+                                          UInt32 bus_number,
+                                          UInt32 num_frames,
+                                          AudioBufferList* io_data) {
+    RTC_LOG(LS_VERBOSE) << __FUNCTION__;
+    [sink_ onRemoteAudioFrameWithFlags:flags timeStamp:time_stamp busNumber:bus_number numFrames:num_frames ioData:io_data];
+  }
+}
+
